"0","#time to clean our data"
"0","#cleaning lib tm comes in action "
"0","# use install.packages(""tm) to add this library"
"0","library(tm)"
"0",""
"0","#convert data to UTF"
"0","newdata<- iconv(df2$text, ""ASCII"", ""UTF-8"", sub="""")"
"0",""
"0","#extract text from the data frame build your own corpus(a corpus is a collection of text files)"
"0","mydata <- Corpus(VectorSource(newdata))"
"0",""
"0","# convert to lower case"
"0","mydata <- tm_map(mydata, content_transformer(tolower))"
"2","transformation drops documents"
"0","#remove ������ what would be emojis"
"0","mydata<-tm_map(mydata, content_transformer(gsub), pattern=""\\W"",replace="" "")"
"2","transformation drops documents"
"0","# remove URLs"
"0","removeURL <- function(x) gsub(""http[^[:space:]]*"", """", x)"
"0","mydata <- tm_map(mydata, content_transformer(removeURL)"
"0","                 )"
"2","transformation drops documents"
"0","# remove anything other than English letters or space"
"0","removeNumPunct <- function(x) gsub(""[^[:alpha:][:space:]]*"", """", x)"
"0","mydata <- tm_map(mydata, content_transformer(removeNumPunct))"
"2","transformation drops documents"
"0","# remove stopwords"
"0","mydata <- tm_map(mydata, removeWords, stopwords(""english""))"
"2","transformation drops documents"
"0","#u can create custom stop words using the code below."
"0","#myStopwords <- c(setdiff(stopwords('english'), c(""r"", ""big"")),""use"", ""see"", ""used"", ""via"", ""amp"")"
"0","#mydata <- tm_map(mydata, removeWords, myStopwords)"
"0",""
"0","# remove extra whitespace"
"0","mydata <- tm_map(mydata, stripWhitespace)"
"2","transformation drops documents"
"0","# Remove numbers"
"0","mydata <- tm_map(mydata, removeNumbers)"
"2","transformation drops documents"
"0","# Remove punctuations"
"0","mydata <- tm_map(mydata, removePunctuation)"
"2","transformation drops documents"
"0","# keep a copy for stem completion later"
"0","mydataCopy <- mydata"
